::alert{type="info"}
此笔记源自 [Chencwx](https://github.com/chencwx) ，原作者享有版权。
::

# 7 机器学习

## 基础理论

本章首先讲述了什么是机器学习以及机器是如何学习的，然后引入了一些机器学习的基本概念。接下来从假设空间和归纳偏好两个方面来讲述模型的产生。最后介绍了机器学习的发展历程以及应用现状。

## 技术框架和研究方法

 **模型评估与选择**

本章首先引入了经验误差和泛化误差的概念，从而很自然地引伸出了机器学习中模型选择的问题。然后通过评估方法、性能度量、比较检验三个章节来讲述模型选择的整个流程。最后还介绍了偏差-方差分解，这可以帮助我们更好地解释模型的泛化性能。

**决策树**

本章首先介绍了决策树模型的结构以及决策树学习的目标，然后自然地引入了在建立树结构时如何选择最优划分属性的问题，并介绍了三种最为常用的指标（信息增益、信息增益率和基尼指数）。针对过拟合问题，作者讲解了预剪枝和后剪枝这两种解决方案以及它们各自的优缺点。接下来还给出了数据集的连续值离散化以及缺失值处理的一些思路。最后简单地介绍了结合线性模型从而实现减少预测时间开销这一目的的多变量决策树模型。

**神经网络**

本章首先介绍了神经网络最基本的组成单位——神经元。然后引入了最简单的只有两层神经元的感知机，并在此基础上又引入了多层网络和多层前馈神经网络的概念。接下来介绍了神经网络的典型学习方法——BP算法，分为标准BP算法和累积BP算法两种。针对过拟合问题和陷入局部最小问题，作者给出了一些比较常见的思路。接下来作者还简单地介绍了一些其他的神经网络模型。在本章的最后，作者简要概述了今年最火的深度学习的思想，以及如何节省训练时间开销。

**支持向量机**

本章首先引入了支持向量机中最基础的两个概念——间隔和支持向量。然后介绍了如何把获取最大间隔超平面转换为对偶问题并使用SMO算法求解。接下来介绍了如何使用核函数来解决线性不可分问题以及有哪些常用的核函数。针对过拟合问题，作者介绍了软间隔这个概念以及软间隔支持向量机的求解方式，并讨论了常用的替代损失函数。接下来，作者介绍了支持向量回归以及对应的求解方法。在本章的最后，作者还介绍了核方法，也即通过引入核函数将线性学习器转换为非线性学习器的方法。

**贝叶斯分类器**

本章首先介绍了贝叶斯决策论的基础，贝叶斯分类器的目标是什么。然后介绍了如何用极大似然估计来估计概率模型的参数。接下来介绍了基于属性条件独立性假设的朴素贝叶斯分类器，以及基于独依赖估计的半朴素贝叶斯分类器。然后又介绍了更为强大的贝叶斯网络，从结构、学习、推断三个方面详细地进行了讲述。最后，针对缺失值问题，作者简要地介绍了EM算法。

**集成学习**

本章首先介绍了集成学习中一些最基本的概念和假设，以及集成学习的两个大类。接下来，作者介绍了几个常用的集成学习算法，包括Boosting算法族的AdaBoost算法，还有并行式集成算法的代表——Bagging算法和随机森林算法。除了这些常用算法之外，从多个基学习器结合的角度出发，作者介绍了一些常用的结合策略。在最后一个小节中，作者从误差-分歧分解的角度解释了为什么基学习器的多样性越大越好，并且介绍了一些多样性的度量指标，最后给出了一些增强多样性的方法。

**聚类**

本章首先介绍了聚类任务的目标和应用方式，然后首先讲述了聚类任务中的两大基本问题——性能度量和距离计算。接下来，作者介绍了三种不同的聚类思想，包括原型聚类、密度聚类和层次聚类，每一种聚类思想都有很多衍生的聚类算法。

**降维**

本章介绍了降维方法，包括k近邻、低维嵌入、主成分分析、核化线性降维、流行学习，后介绍度量学习。首先从“维数灾难”导致的样本稀疏以及距离难计算两大难题出发，引出了降维的概念，即通过某种数学变换将原始高维空间转变到一个低维的子空间，接着分别介绍了kNN、MDS、PCA、KPCA以及两种经典的流形学习方法，k近邻算法的核心在于k值的选取以及距离的度量，MDS要求原始空间样本之间的距离在降维后的低维空间中得以保持，主成分分析试图找到一个低维超平面来表出原空间样本点，**主成分分析先将样本点映射到高维空间，再在高维空间中使用线性降维的方法，从而解决了原空间样本非线性分布的情形**，基于流形学习的降维则是一种“邻域保持”的思想，最后度量学习试图去学习出一个距离度量来等效降维的效果。

**强化学习**

强化学习是机器学习的一个重要分支，前段时间人机大战的主角AlphaGo正是以强化学习为核心技术。在强化学习中，包含两种基本的元素：状态与动作，在某个状态下执行某种动作，这便是一种策略，学习器要做的就是通过不断地探索学习，从而获得一个好的策略。例如：在围棋中，一种落棋的局面就是一种状态，若能知道每种局面下的最优落子动作，那就攻无不克/百战不殆了若将状态看作为属性，动作看作为标记，易知：监督学习和强化学习都是在试图寻找一个映射，从已知属性/状态推断出标记/动作，这样强化学习中的策略相当于监督学习中的分类/回归器。但在实际问题中，强化学习并没有监督学习那样的标记信息，通常都是在尝试动作后才能获得结果，因此强化学习是通过反馈的结果信息不断调整之前的策略，从而算法能够学习到：在什么样的状态下选择什么样的动作可以获得最好的结果
