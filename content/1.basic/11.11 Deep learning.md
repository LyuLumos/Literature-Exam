::alert{type="info"}
此笔记源自 [Chencwx](https://github.com/chencwx) ，原作者享有版权。
::

# 11 Deep learning

>[11]GOODFELLOW I, BENGIO Y, COURVILLE A, et al. Deep learning[M]. Cambridge: The MIT Press, 2016.



### 科学问题

- 本书讨论的科学问题可分为三部分：
  - 第一部分介绍基本的数学工具和机器学习的概念；
  - 第二部分介绍最成熟的深度学习算法，这些技术基本上已经得到解决；
  - 第三部分讨论某些具有展望性的想法，它们被广泛地认为是深度学习未来的研究重点。


### 基础理论

- 机器学习定义：对于某类任务 T 和性能度量 P，一个计算机程序被认为可以从经验 E 中学习是指，通过经验 E 改进后，它在任务 T 上由性能度量 P衡量的性能有所提升。
- 无监督学习算法训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。 在深度学习中，我们通常要学习生成数据集的整个概率分布。还有一些其他类型的无监督学习任务，例如聚类，会将数据集分成相似样本的集合。
- 监督学习算法训练含有很多特征的数据集，不过数据集中的样本都有一个标签或目标。
- 欠拟合是指模型不能在训练集上获得足够低的误差。 而过拟合是指训练误差和和测试误差之间的差距太大。
- 深度学习（deep learning）通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。

### 技术框架/关键技术


- 韦恩图表示深度学习地位：（（（（深度学习）表示学习）机器学习）AI）
- 深度学习是表示学习中的一种，在它的基础上多了这一部分：**自动提取特征**。
- 神经网络的发展分为几个阶段，第一个是单层网络，第二个两层，第三个多层。这三层网络在激活函数、异或问题和复杂问题上有所不同。
- 单层网络只有两种状态，激活或者抑制，是一个函数值是1或者-1的符号函数，无法解决异或函数和复杂问题。
- 两层网络的结构更复杂，激活函数不再是符号函数，而是sigmoid，可以解决异或问题，但是解决不了复杂问题。
- 多层网络，也就是现在的深度学习，激活函数主要是ReLU，可以解决异或问题和复杂问题。
- 深度学习知名的网络结构主要两种：
  - 第一种是前馈，信息从一层一层往下流动，一路向前不回头（不算误差反向传播）。以CNN为例；
  - 第二种是反馈，即把上一次训练的状态留下来，作为本次的一个输入，它是前馈的一种扩展，特点是训练时会把上一次训练结果拿过来用，再决定下一步的训练。典型例子就是RNN。

- 常见算法**CNN**：
  - CNN被设计用于处理以多阵列形式出现的数据，信号、语言、序列使用1D，图像或声谱图使用2D，视频、体积图像使用3D。它有四个关键思想，利用了自然信号的特性：本地链接、共享权重、池化和多层的使用。最早起源于1990s早期，应用于语音识别、图像检测。
  - 典型架构：卷积、非线性(ReLU)和池化的两个或三个阶段是堆叠的，然后是更多卷积和完全连接的层，允许训练网络中的所有权重值。卷积和池化直接受到视觉神经科学的启发。
  - 卷积层：提取特征。“不全连接，参数共享”的特点大大降低了网络参数，保证了网络的稀疏性，防止过拟合。之所以可以“参数共享”，是因为样本存在局部相关的特性。特征图中的所有单元共享相同的滤波器组。一层中的不同特征映射使用不同的滤波器组。
  - 池化层：有MaxPool和AveragePool等。其中MaxPool应用广泛。因为经过MaxPool可以减小卷积核的尺寸，同时又可以保留相应特征，所以主要用来降维。池化层的作用是将语义相似的特征合并成一个
  - 许多自然信号中较高层次是由较低层次的特征组成的。前一层元素的位置和外观的变化所引起的池的变动非常小


### 研究方法

- 该书通过研究大量的文献进行总结，对深度学习的整体领域进行了由浅入深的讲解。
- 目前主要有两种度量模型深度的方式：
  - 一种是基于评估架构所需执行的顺序指令的数目。深度是从输入到输出的最长路径的长度，但这取决于可能的计算步骤的定义。
  - 另一种是将描述概念彼此如何关联的图的深度视为模型深度。
- 深度学习基本模型：
  - 可见层（visible layer），它包含我们能观察到的变量。
  - 隐藏层（hidden layer）， 它们的值不在数据中给出。
  - 输出层（output layer），识别存在的对象。



### 前沿进展/研究进展

- 人和动物的学习都是无监督的，我们通过观察世界发现来发现世界的结构，而不是因为被告知了物体相应的名称。
- 虽然结合了深度学习和强化学习的系统还处于初级阶段，但它们在分类任务上的表现已经超过了被动视觉系统。
- 另外，预言深度学习会在NLP、语音识别和手写识别上会变得越来越好。

### 创新建议

- 书中已经介绍了如何解决监督学习问题，即在给定足够的映射样本的情况下，学习将一个向量映射到另一个。但是想要解决的问题并不全都属于这个类别。我们可能希望生成新的样本、或确定一个点的似然性、或处理缺失值以及利用一组大量的未标记样本或相关任务的样本。
- 当前应用于工业的最先进技术的缺点是我们的学习算法需要**大量的监督数据**才能实现良好的精度。实现这些目标通常需要某种形式的无监督或半监督学习。
- 无监督学习困难的核心原因是被建模的随机变量的高维度。这带来了两个不同的挑战：统计挑战和计算挑战。
  - 计算挑战来自执行难解的推断或难解的归一化分布，难解的推断主要在第十九章近似推断中讨论；难解的归一化常数通过第十八章讨论的配分函数来解决，第十七章介绍的马尔可夫链蒙特卡罗方法通常用来处理配分函数。上面这些方法的核心思想是面对这些难以处理的计算，通过近似它们的方式来处理。
  - 而解决计算挑战的另一种有趣的方式是通过设计模型，完全避免这些难以处理的计算，因此不需要这些计算的方法是非常有吸引力的。

